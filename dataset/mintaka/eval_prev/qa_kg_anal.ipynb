{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer_raw</th>\n",
       "      <th>answers</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>raw_result</th>\n",
       "      <th>pred</th>\n",
       "      <th>acc</th>\n",
       "      <th>hit</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>{'answerType': 'entity', 'answer': [{'name': '...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>mark twain</td>\n",
       "      <td>0</td>\n",
       "      <td>---Direct Answer---: Mark Twain\\n---Brief Anal...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>{'answerType': 'numerical', 'answer': [1], 'me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>---Direct Answer---: 0 | 0\\n---Brief Analysis-...</td>\n",
       "      <td>0 | 0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What man was a famous American author and also...   \n",
       "1  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "\n",
       "                                          answer_raw     answers       label  \\\n",
       "0  {'answerType': 'entity', 'answer': [{'name': '...  Mark Twain  mark twain   \n",
       "1  {'answerType': 'numerical', 'answer': [1], 'me...           1           1   \n",
       "\n",
       "   id                                         raw_result        pred  acc  \\\n",
       "0   0  ---Direct Answer---: Mark Twain\\n---Brief Anal...  Mark Twain  1.0   \n",
       "1   1  ---Direct Answer---: 0 | 0\\n---Brief Analysis-...       0 | 0  0.0   \n",
       "\n",
       "   hit   f1  precision  recall  \n",
       "0    1  0.4       0.25     1.0  \n",
       "1    0  0.0       0.00     0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "project_path = \"/home/wangshu/rag/hier_graph_rag\"\n",
    "sys.path.append(os.path.abspath(project_path))\n",
    "\n",
    "\n",
    "direct_res_path = \"/mnt/data/wangshu/hcarag/mintaka/hcarag/hc_index_8b/qa/global_10_20_20_15_mr_QA_.csv\"\n",
    "direct_df = pd.read_csv(direct_res_path)\n",
    "entity_df_path = \"/mnt/data/wangshu/hcarag/mintaka/hcarag/hc_index_8b/entity_df_index.csv\"\n",
    "entity_df = pd.read_csv(entity_df_path)\n",
    "community_df_path = \"/mnt/data/wangshu/hcarag/mintaka/hcarag/hc_index_8b/community_df_index.csv\"\n",
    "community_df = pd.read_csv(community_df_path)\n",
    "\n",
    "direct_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diana Ross Diana Ross (born March 26, 1944) is an American singer and actress. She was the lead sing\n"
     ]
    }
   ],
   "source": [
    "entity_df[\"node_description\"] = entity_df[\"name\"] + \" \" + entity_df[\"description\"]\n",
    "entity_df_description = entity_df[\"node_description\"].values\n",
    "entity_df_description = \" \".join(entity_df_description)\n",
    "print(entity_df_description[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The community revolves around the Green Valley Mall, which is a central location for various events \n"
     ]
    }
   ],
   "source": [
    "community_df[\"community_desc\"] = community_df[\"summary\"] + \" \" + community_df[\"title\"]\n",
    "c_df_desc = community_df[\"community_desc\"].values\n",
    "community_content = \" \".join([c for c in c_df_desc if type(c) == str])\n",
    "print(community_content[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278.10692498491653\n",
      "349.5613034229356\n"
     ]
    }
   ],
   "source": [
    "text_length = []\n",
    "for _, row in community_df.iterrows():\n",
    "    if type(row[\"community_desc\"]) is str:\n",
    "        text_length.append(len(row[\"community_desc\"]))\n",
    "\n",
    "community_mean_text_length = sum(text_length) / len(text_length)\n",
    "print(community_mean_text_length)\n",
    "\n",
    "text_length_entity = []\n",
    "for _, row in entity_df.iterrows():\n",
    "    text_length_entity.append(len(row[\"node_description\"]))\n",
    "entity_mean_text_length = sum(text_length_entity) / len(text_length_entity)\n",
    "print(entity_mean_text_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [03:04, 21.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of question: 4000\n",
      "entity ratio: 0.431\n",
      "community ratio: 0.37775\n",
      "both answer ratio: 0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnt_entity = 0\n",
    "cnt_community = 0\n",
    "cnt_both = 0\n",
    "\n",
    "for _, row in tqdm(direct_df.iterrows()):\n",
    "    answer = row[\"label\"]\n",
    "    \n",
    "    if answer in entity_df_description:\n",
    "        cnt_entity += 1\n",
    "    \n",
    "    if answer in community_content:\n",
    "        cnt_community += 1\n",
    "    \n",
    "    if answer in entity_df_description or answer in community_content:\n",
    "        cnt_both += 1\n",
    "        \n",
    "print(f\"number of question: {len(direct_df)}\")\n",
    "    \n",
    "print(f\"entity ratio: {cnt_entity / len(direct_df)}\")\n",
    "print(f\"community ratio: {cnt_community / len(direct_df)}\")\n",
    "print(f\"both answer ratio: {cnt_both / len(direct_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intersection' 'count' 'comparative' 'yesno' 'generic' 'ordinal'\n",
      " 'multihop' 'difference' 'superlative']\n",
      "(2800, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_label</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>history</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'answerType': 'entity', 'answer': [{'name': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b41ae115</td>\n",
       "      <td>Who performed at the Super Bowl XXIII halftime...</td>\n",
       "      <td>Elvis Presto</td>\n",
       "      <td>sports</td>\n",
       "      <td>generic</td>\n",
       "      <td>{'answerType': 'entity', 'answer': None, 'ment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question  answer_label  \\\n",
       "0  fae46b21  What man was a famous American author and also...    Mark Twain   \n",
       "5  b41ae115  Who performed at the Super Bowl XXIII halftime...  Elvis Presto   \n",
       "\n",
       "  category complexityType                                             answer  \n",
       "0  history   intersection  {'answerType': 'entity', 'answer': [{'name': '...  \n",
       "5   sports        generic  {'answerType': 'entity', 'answer': None, 'ment...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_qa_df_ori = \"/mnt/data/wangshu/hcarag/mintaka/data/mintaka_test.json\"\n",
    "qa_df_ori = pd.read_json(path_qa_df_ori)\n",
    "\n",
    "qa_df_ori[\"answer_label\"] = qa_df_ori[\"answer\"].apply(lambda x: x[\"mention\"])\n",
    "qa_df_ori = qa_df_ori[[\"id\", \"question\", \"answer_label\", \"category\", \"complexityType\",\"answer\"]]\n",
    "sel_comples = [\n",
    "    \"superlative\",\n",
    "    \"ordinal\",\n",
    "    \"multihop\",\n",
    "    \"intersection\",\n",
    "    \"difference\",\n",
    "    \"generic\",\n",
    "]\n",
    "\n",
    "print(qa_df_ori[\"complexityType\"].unique())\n",
    "sel_qa_df = qa_df_ori[qa_df_ori[\"complexityType\"].isin(sel_comples)]\n",
    "print(sel_qa_df.shape)\n",
    "\n",
    "sel_qa_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_label</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>61216214</td>\n",
       "      <td>Which 2000 Christopher Nolan movie does not st...</td>\n",
       "      <td>Memento</td>\n",
       "      <td>movies</td>\n",
       "      <td>difference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>c3f408f4</td>\n",
       "      <td>Which 2020 Christopher Nolan movie does not st...</td>\n",
       "      <td>Tenet</td>\n",
       "      <td>movies</td>\n",
       "      <td>difference</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           question answer_label  \\\n",
       "76  61216214  Which 2000 Christopher Nolan movie does not st...      Memento   \n",
       "77  c3f408f4  Which 2020 Christopher Nolan movie does not st...        Tenet   \n",
       "\n",
       "   category complexityType  \n",
       "76   movies     difference  \n",
       "77   movies     difference  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_def = qa_df_ori[qa_df_ori['complexityType']== \"difference\"]\n",
    "sel_def.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2032it [00:01, 1668.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "0.2534448818897638\n",
      "2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnt_gr = 0\n",
    "\n",
    "direct_df['answers_lists'] = direct_df['answers'].apply(lambda x: eval(x))\n",
    "gr_base_path = \"/mnt/data/wangshu/hcarag/FB15k/KG/cached_desc/\"\n",
    "\n",
    "for idx, row in tqdm(direct_df.iterrows()):\n",
    "    answer = row[\"answers_lists\"]\n",
    "    with open(gr_base_path + str(idx) + \".txt\", \"r\") as f:\n",
    "        gr_text = f.read()\n",
    "    for ans in answer:\n",
    "        if ans in gr_text:\n",
    "            cnt_gr += 1\n",
    "            break\n",
    "    \n",
    "print(cnt_gr) \n",
    "print(cnt_gr / len(direct_df))\n",
    "print(len(direct_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
