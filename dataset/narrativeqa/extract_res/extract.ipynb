{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1102/1102 [00:02<00:00, 429.99it/s]\n",
      "100%|██████████| 355/355 [00:01<00:00, 266.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_1pred: 2.0256\n",
      "bleu_4pred: 0.0026\n",
      "modify_bleu_4pred: 0.0052\n",
      "bleu_1_smoothpred: 2.0256\n",
      "bleu_4_smoothpred: 0.0342\n",
      "modify_bleu_4_smoothpred: 0.1063\n",
      "meteorpred: 4.8877\n",
      "rouge_l_f1pred: 2.7946\n",
      "rouge_l_precisionpred: 1.5887\n",
      "rouge_l_recallpred: 29.6738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_path = \"/mnt/data/wangshu/hcarag/narrativeqa/data\"\n",
    "train_base = os.path.join(base_path, \"train\")\n",
    "test_base = os.path.join(base_path, \"test\")\n",
    "\n",
    "train_max = 1101\n",
    "test_max = 354\n",
    "\n",
    "\n",
    "def get_merged_res(path_suffix):\n",
    "    all_df = pd.DataFrame()\n",
    "\n",
    "    # Trian\n",
    "    for i in tqdm(range(train_max + 1)):\n",
    "        path = os.path.join(train_base, str(i), path_suffix)\n",
    "        if os.path.exists(path):\n",
    "            tmp_df = pd.read_csv(path)\n",
    "            all_df = pd.concat([all_df, tmp_df])\n",
    "\n",
    "    # Test\n",
    "    for i in tqdm(range(test_max + 1)):\n",
    "        path = os.path.join(test_base, str(i), path_suffix)\n",
    "        if os.path.exists(path):\n",
    "            tmp_df = pd.read_csv(path)\n",
    "            all_df = pd.concat([all_df, tmp_df])\n",
    "    \n",
    "    metrics_attr = []\n",
    "    for col in all_df.columns:\n",
    "        if col.startswith(\"bleu\"):\n",
    "            metrics_attr.append(col)\n",
    "        elif col.startswith(\"rouge\"):\n",
    "            metrics_attr.append(col)\n",
    "        elif col.startswith(\"meteor\"):\n",
    "            metrics_attr.append(col)\n",
    "        elif col.startswith(\"modify\"):\n",
    "            metrics_attr.append(col)\n",
    "            \n",
    "    sel_df = all_df[metrics_attr]\n",
    "    avg_metrics = sel_df.mean()\n",
    "    # print each metric\n",
    "    for idx, val in avg_metrics.items():\n",
    "        print(f\"{idx}: {val*100:.4f}\")\n",
    "    return avg_metrics\n",
    "    \n",
    "# suffix = \"qa_dataset/graphrag_local.csv\"    \n",
    "# suffix = \"qa_dataset/villa_rag_llama3.1:8b4k_top5.csv\"    \n",
    "suffix = \"qa_dataset/BM25_rag_llama3.1:8b4k_top5.csv\"    \n",
    "# suffix = \"hcarag/hc_index_8b/qa/global_False_3_15_5_15_False_mr_QA_False_0.csv\"    \n",
    "avg_metrics = get_merged_res(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = (\n",
    "    \"/mnt/data/wangshu/hcarag/narrativeqa/data/train/0/qa_dataset/graphrag_global.csv\"\n",
    ")\n",
    "\n",
    "tmp_df = pd.read_csv(base_path)\n",
    "tmp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1457 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1457/1457 [00:00<00:00, 13792.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 95242793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95242793"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "# extract all used token from log file inference\n",
    "\n",
    "\n",
    "def extract_all_token(base_dir, token_line_pattern: str, sel_file_pattern: str = None):\n",
    "    all_tokens = 0\n",
    "    all_files = os.listdir(base_dir)\n",
    "\n",
    "    if sel_file_pattern is not None:\n",
    "        all_files = [f for f in all_files if f.endswith(sel_file_pattern)]\n",
    "\n",
    "    print(f\"Total files: {len(all_files)}\")\n",
    "    \n",
    "    for f in tqdm(all_files):\n",
    "        f_path = os.path.join(base_dir, f)\n",
    "        with open(f_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if token_line_pattern in line:\n",
    "                    tokens = int(line.split()[-1])\n",
    "                    all_tokens += tokens\n",
    "                    break\n",
    "\n",
    "    print(f\"Total tokens: {all_tokens}\")\n",
    "    return all_tokens\n",
    "\n",
    "\n",
    "# base_dir = \"/home/wangshu/rag/hier_graph_rag/dataset/narrativeqa/eval/evaluate_t0.1_global_3_15_5_15_mr_QA_False_0\"\n",
    "\n",
    "\n",
    "# # GraphRAG\n",
    "# base_dir = \"/home/wangshu/rag/hier_graph_rag/other_baseline/graphrag/eval_narrative\"\n",
    "# # sel_file_pattern = \"-docqa-toke_usage.log\"\n",
    "# sel_file_pattern = \"-localdocqa-toke_usage.log\"\n",
    "\n",
    "# villa-rag\n",
    "# base_dir = \"/home/wangshu/rag/hier_graph_rag/other_baseline/villa-rag/narrative_eval_res\"\n",
    "# sel_file_pattern = \"-5-llama3.1:8b4k.log\"\n",
    "\n",
    "base_dir = \"/home/wangshu/rag/hier_graph_rag/other_baseline/simple_BM25/narrative_eval_res\"\n",
    "sel_file_pattern = \"-5-llama3.1:8b4k.log\"\n",
    "token_line_pattern = \"Total token\"\n",
    "\n",
    "extract_all_token(base_dir, token_line_pattern, sel_file_pattern=sel_file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 25536517\n",
      "Create graph tokens: 14293472\n"
     ]
    }
   ],
   "source": [
    "# extract index token from log file\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "tmp_log_file_path = \"/mnt/data/wangshu/hcarag/HotpotQA/graphrag_io/output/20240927-191252/reports/indexing-engine.log\"\n",
    "\n",
    "\n",
    "def extract_index_token(log_file_path: str):\n",
    "    create_graph_line = \"INFO dependencies for create_final_community_reports:\"\n",
    "    all_tokens = 0\n",
    "    create_graph_tokens = 0\n",
    "    get_create_graph = False\n",
    "    token_pattern = re.compile(r'input_tokens=(\\d+), output_tokens=(\\d+)')\n",
    "    \n",
    "    with open(log_file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = token_pattern.search(line)\n",
    "            if match:\n",
    "                input_tokens = int(match.group(1))\n",
    "                output_tokens = int(match.group(2))\n",
    "                total_tokens = input_tokens + output_tokens\n",
    "                all_tokens += total_tokens\n",
    "            if (get_create_graph is False) and  (create_graph_line in line):\n",
    "                get_create_graph = True\n",
    "                create_graph_tokens = all_tokens\n",
    "    print(f\"Total tokens: {all_tokens}\")\n",
    "    print(f\"Create graph tokens: {create_graph_tokens}\")\n",
    "    return all_tokens, create_graph_tokens\n",
    "\n",
    "all_tokens, create_graph_tokens = extract_index_token(tmp_log_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
